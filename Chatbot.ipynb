{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjQP-KdZynw7",
        "outputId": "703665f7-a8de-43b3-e5c8-8c6d814028cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading movie-dialog-corpus.zip to /content\n",
            "\r  0% 0.00/8.91M [00:00<?, ?B/s]\r 56% 5.00M/8.91M [00:00<00:00, 32.3MB/s]\n",
            "\r100% 8.91M/8.91M [00:00<00:00, 46.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d Cornell-University/movie-dialog-corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5v-cLqKy-EK",
        "outputId": "646841b6-b468-4c04-e66b-a59adcffd501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/movie-dialog-corpus.zip\n",
            "  inflating: README.txt              \n",
            "  inflating: movie_characters_metadata.tsv  \n",
            "  inflating: movie_conversations.tsv  \n",
            "  inflating: movie_lines.tsv         \n",
            "  inflating: movie_titles_metadata.tsv  \n",
            "  inflating: raw_script_urls.tsv     \n"
          ]
        }
      ],
      "source": [
        "! unzip '/content/movie-dialog-corpus.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQtfIAgOeMf7"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2mSq9lWeKj3",
        "outputId": "edf48c5d-6626-444e-f7cc-76f98e334819"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import re\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense , Flatten , Embedding, Input, LSTM, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.initializers import Constant\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdlTktVB-YOt"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM8PTt3izDBZ"
      },
      "outputs": [],
      "source": [
        "lines = open('/content/movie_lines.tsv', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "convos = open('/content/movie_conversations.tsv', encoding='utf-8', errors='ignore').read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f2dkx4H-sla",
        "outputId": "8304807e-23d4-4200-e4dd-ab684d6a38b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "u0\tu2\tm0\t['L194' 'L195' 'L196' 'L197']\n",
            "u0\tu2\tm0\t['L198' 'L199']\n",
            "u0\tu2\tm0\t['L200' 'L201' 'L202' 'L203']\n",
            "u0\tu2\tm0\t['L204' 'L205' 'L206']\n",
            "u0\tu2\tm0\t['L207' 'L208']\n"
          ]
        }
      ],
      "source": [
        "for i in convos[:5]:\n",
        "  print(i,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl2bNsDb-tt-",
        "outputId": "10d895dc-736c-4bf5-cdcd-44553228bd3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L1045\tu0\tm0\tBIANCA\tThey do not!\n",
            "L1044\tu2\tm0\tCAMERON\tThey do to!\n",
            "L985\tu0\tm0\tBIANCA\tI hope so.\n",
            "L984\tu2\tm0\tCAMERON\tShe okay?\n",
            "L925\tu0\tm0\tBIANCA\tLet's go.\n"
          ]
        }
      ],
      "source": [
        "for i in lines[:5]:\n",
        "  print(i,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpOC3mbZ-3Ry"
      },
      "outputs": [],
      "source": [
        "exchange = []\n",
        "\n",
        "for conv in convos:\n",
        "  exchange.append(conv.split('\\t')[-1][1:-1].replace(\"'\",\"\").split(' '))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoLLXrjt--mh",
        "outputId": "a4ed2372-44e7-408c-862e-8646e28ba645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['L194', 'L195', 'L196', 'L197']\n",
            "['L198', 'L199']\n",
            "['L200', 'L201', 'L202', 'L203']\n",
            "['L204', 'L205', 'L206']\n",
            "['L207', 'L208']\n"
          ]
        }
      ],
      "source": [
        "for i in exchange[:5]:\n",
        "  print(i,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6eHAyAEAEmc"
      },
      "outputs": [],
      "source": [
        "dialogues = {}\n",
        "\n",
        "for line in lines:\n",
        "  temp = line.split('\\t')\n",
        "  dialogues[temp[0].replace('\"','')] = temp[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBhSte3mAQLh",
        "outputId": "63cd1a5a-62df-410b-cb2f-ce073c69b421"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'L1045': 'They do not!',\n",
              " 'L1044': 'They do to!',\n",
              " 'L985': 'I hope so.',\n",
              " 'L984': 'She okay?',\n",
              " 'L925': \"Let's go.\"}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import itertools\n",
        "dict(itertools.islice(dialogues.items(), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1BcYbjSW1cD"
      },
      "outputs": [],
      "source": [
        "del (conv, convos, i, line, lines, temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMdRR4UHBx3b"
      },
      "outputs": [],
      "source": [
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for i in exchange:\n",
        "  for j in range(len(i)-1):\n",
        "    questions.append(dialogues[i[j]])\n",
        "    answers.append(dialogues[i[j+1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "533KBCynZKeU",
        "outputId": "240972dc-f45a-46fb-da4f-7855f7c31f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. ----> Well I thought we'd start with pronunciation if that's okay with you.\n",
            "\n",
            "2. Well I thought we'd start with pronunciation if that's okay with you. ----> Not the hacking and gagging and spitting part.  Please.\n",
            "\n",
            "3. Not the hacking and gagging and spitting part.  Please. ----> Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
            "\n",
            "4. You're asking me out.  That's so cute. What's your name again? ----> Forget it.\n",
            "\n",
            "5. No no it's my fault -- we didn't have a proper introduction --- ----> Cameron.\n",
            "\n",
            "6. Cameron. ----> The thing is Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
            "\n",
            "7. The thing is Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. ----> Seems like she could get a date easy enough...\n",
            "\n",
            "8. Why? ----> Unsolved mystery.  She used to be really popular when she started high school then it was just like she got sick of it or something.\n",
            "\n",
            "9. Unsolved mystery.  She used to be really popular when she started high school then it was just like she got sick of it or something. ----> That's a shame.\n",
            "\n",
            "10. Gosh if only we could find Kat a boyfriend... ----> Let me see what I can do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(f'{i+1}. {questions[i]} ----> {answers[i]}',end='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBLKlQDcbFZ1"
      },
      "outputs": [],
      "source": [
        "# keep only those questions and answers whose length is less than threshold\n",
        "\n",
        "threshold = 75\n",
        "filter_que = []\n",
        "filter_ans = []\n",
        "\n",
        "for i in range(len(questions)):\n",
        "  if len(questions[i])<=threshold:\n",
        "    if len(answers[i])<=threshold:\n",
        "      filter_que.append(questions[i])\n",
        "      filter_ans.append(answers[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZbhHdCxcebF",
        "outputId": "398c0fd6-f66e-43b0-8b06-505d6f6dcd34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Well I thought we'd start with pronunciation if that's okay with you. ----> Not the hacking and gagging and spitting part.  Please.\n",
            "\n",
            "2. Not the hacking and gagging and spitting part.  Please. ----> Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
            "\n",
            "3. You're asking me out.  That's so cute. What's your name again? ----> Forget it.\n",
            "\n",
            "4. No no it's my fault -- we didn't have a proper introduction --- ----> Cameron.\n",
            "\n",
            "5. Gosh if only we could find Kat a boyfriend... ----> Let me see what I can do.\n",
            "\n",
            "6. C'esc ma tete. This is my head ----> Right.  See?  You're ready for the quiz.\n",
            "\n",
            "7. That's because it's such a nice one. ----> Forget French.\n",
            "\n",
            "8. How is our little Find the Wench A Date plan progressing? ----> Well there's someone I think might be --\n",
            "\n",
            "9. There. ----> Where?\n",
            "\n",
            "10. You have my word.  As a gentleman ----> You're sweet.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(f'{i+1}. {filter_que[i]} ----> {filter_ans[i]}',end='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFbHXFTwdiNf"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"\\'m\", \" am\", text)\n",
        "  text = re.sub(r\"\\'s\", \" is\", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\n",
        "  text = re.sub(r\" 'bout\", \" about\", text)\n",
        "  text = re.sub(r\"gonna\", \"going to\", text)\n",
        "  text = re.sub(r\"gotta\", \"got to\", text)\n",
        "  text = re.sub(r\"won't\", \"will not\", text)\n",
        "  text = re.sub(r\"can't\", \"can not\", text)\n",
        "  text = re.sub(r\"n't\", \" not\", text)\n",
        "  text = re.sub(\"\\d+\",\"\",text) # remove numbers\n",
        "  text = re.sub(r\"[^\\w\\s]\", \"\", text) # remove punctuations\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrrbNz-Sim-3"
      },
      "outputs": [],
      "source": [
        "frame = [filter_que,filter_ans]\n",
        "df = pd.DataFrame(frame, index=['questions', 'answers']).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfsW2of9jEC8",
        "outputId": "273b8f7a-f78e-4195-ff82-6c8b492041f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(137344, 2)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cESZA-hzw8tO",
        "outputId": "d7cfe0ba-8ad5-45f5-8e53-80438e047b81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-380fca52-5170-4a42-a300-eb18362f7d0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Well I thought we'd start with pronunciation i...</td>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "      <td>Okay... then how 'bout we try out some French ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
              "      <td>Forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No no it's my fault -- we didn't have a proper...</td>\n",
              "      <td>Cameron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gosh if only we could find Kat a boyfriend...</td>\n",
              "      <td>Let me see what I can do.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-380fca52-5170-4a42-a300-eb18362f7d0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-380fca52-5170-4a42-a300-eb18362f7d0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-380fca52-5170-4a42-a300-eb18362f7d0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           questions  \\\n",
              "0  Well I thought we'd start with pronunciation i...   \n",
              "1  Not the hacking and gagging and spitting part....   \n",
              "2  You're asking me out.  That's so cute. What's ...   \n",
              "3  No no it's my fault -- we didn't have a proper...   \n",
              "4      Gosh if only we could find Kat a boyfriend...   \n",
              "\n",
              "                                             answers  \n",
              "0  Not the hacking and gagging and spitting part....  \n",
              "1  Okay... then how 'bout we try out some French ...  \n",
              "2                                         Forget it.  \n",
              "3                                           Cameron.  \n",
              "4                          Let me see what I can do.  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYdWCBaQfpHu"
      },
      "outputs": [],
      "source": [
        "df['questions'] = df['questions'].apply(clean_text)\n",
        "df['answers'] = df['answers'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j9LL6xfYj1vU",
        "outputId": "3754d2f2-1da1-4d89-c7d3-acd0c57e5235"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4ec21b70-0170-496a-8ba8-553ccb2b7366\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>well i thought we would start with pronunciati...</td>\n",
              "      <td>not the hacking and gagging and spitting part ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not the hacking and gagging and spitting part ...</td>\n",
              "      <td>okay then how about we try out some french cui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you are asking me out  that is so cute what is...</td>\n",
              "      <td>forget it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no no it is my fault  we did not have a proper...</td>\n",
              "      <td>cameron</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gosh if only we could find kat a boyfriend</td>\n",
              "      <td>let me see what i can do</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ec21b70-0170-496a-8ba8-553ccb2b7366')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ec21b70-0170-496a-8ba8-553ccb2b7366 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ec21b70-0170-496a-8ba8-553ccb2b7366');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           questions  \\\n",
              "0  well i thought we would start with pronunciati...   \n",
              "1  not the hacking and gagging and spitting part ...   \n",
              "2  you are asking me out  that is so cute what is...   \n",
              "3  no no it is my fault  we did not have a proper...   \n",
              "4         gosh if only we could find kat a boyfriend   \n",
              "\n",
              "                                             answers  \n",
              "0  not the hacking and gagging and spitting part ...  \n",
              "1  okay then how about we try out some french cui...  \n",
              "2                                          forget it  \n",
              "3                                            cameron  \n",
              "4                           let me see what i can do  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGzJhnThuii_"
      },
      "outputs": [],
      "source": [
        "# del (answers,dialogues,exchange,frame,questions,threshold,i,j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04370ELP8iU1"
      },
      "outputs": [],
      "source": [
        "merge = pd.concat([df['questions'], df['answers']], axis = 0).drop_duplicates(keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4uYeDGhklZA",
        "outputId": "3125a30e-0aec-4c5d-f457-eafd8c09c378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "167286\n"
          ]
        }
      ],
      "source": [
        "# create list of sentences in both columns to train word2vec. eg: [['i','am']['you','are']]\n",
        "\n",
        "sentences=[]\n",
        "for each in merge:\n",
        "  sents = word_tokenize(each)\n",
        "  sentences.append(sents)\n",
        "\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYGiOYD-u3SL",
        "outputId": "2f70cbc4-7c41-429f-c8a6-00c48e1cb5e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['well', 'i', 'thought', 'we', 'would', 'start', 'with', 'pronunciation', 'if', 'that', 'is', 'okay', 'with', 'you']\n",
            "\n",
            "['not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', 'please']\n",
            "\n",
            "['you', 'are', 'asking', 'me', 'out', 'that', 'is', 'so', 'cute', 'what', 'is', 'your', 'name', 'again']\n",
            "\n",
            "['no', 'no', 'it', 'is', 'my', 'fault', 'we', 'did', 'not', 'have', 'a', 'proper', 'introduction']\n",
            "\n",
            "['gosh', 'if', 'only', 'we', 'could', 'find', 'kat', 'a', 'boyfriend']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in sentences[:5]:\n",
        "  print(f'{i}',end='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCKM7h001ULZ"
      },
      "outputs": [],
      "source": [
        "# add <start> <end> in word2vec as well because its needed in decoder model\n",
        "\n",
        "for i in range(100,150000,100):\n",
        "  sentences[i].insert(0,\"<START>\")\n",
        "  sentences[i].insert(len(sentences[i]),\"<END>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgWT7qZk4Yig",
        "outputId": "5cc15564-6e1a-4244-beed-d5b9f2fd870d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(8201166, 12145730)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_model = gensim.models.Word2Vec(sentences=sentences,size=300,window=10,min_count=1)\n",
        "w2v_model.train(sentences,epochs=10,total_examples=len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcjOHzgG_gbi",
        "outputId": "a502337c-bc40-48dc-c15a-519d4a2750fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('her', 0.5625358819961548),\n",
              " ('mother', 0.5089250802993774),\n",
              " ('he', 0.4928358793258667),\n",
              " ('girl', 0.48948782682418823),\n",
              " ('mom', 0.442224383354187),\n",
              " ('abated', 0.441238135099411),\n",
              " ('it', 0.43279749155044556),\n",
              " ('wife', 0.4303394854068756),\n",
              " ('woman', 0.42923516035079956),\n",
              " ('nobody', 0.42373526096343994)]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_model.wv.most_similar('she')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G59U5W_X_kpw",
        "outputId": "64770c42-bfb4-4a19-c21c-1f9f25a589ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total number of words are :  34469\n"
          ]
        }
      ],
      "source": [
        "vocab=w2v_model.wv.vocab\n",
        "print(\"The total number of words are : \",len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcIfF4lQ_zsT",
        "outputId": "bc8c6af4-4ef1-427a-dee6-a1888f3cd5fb"
      },
      "outputs": [],
      "source": [
        "word_count = {}\n",
        "for each in sentences:\n",
        "  for i in each:\n",
        "    if i not in word_count:\n",
        "      word_count[i] = 1\n",
        "    else:\n",
        "      word_count[i] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBbhxBHEHofi",
        "outputId": "95948bb5-ecd7-4c8d-f627-904118442ba8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13014"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# keep only those words whose frequency is greater than threshold\n",
        "\n",
        "thresh = 3\n",
        "vocab_dict={}\n",
        "\n",
        "for word,count in word_count.items():\n",
        "  if count >= thresh:\n",
        "    vocab_dict[word] = w2v_model.wv.get_vector(word)\n",
        "\n",
        "len(vocab_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1PYhz-kYCcB",
        "outputId": "d87bc209-f0c9-45dd-d0c8-b4d2f6b13807"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13015"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# add <out> for the words that are left out from vocab_dict\n",
        "\n",
        "vocab_dict['<OUT>'] = np.zeros(300)\n",
        "len(vocab_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa2mJKDpKW3f"
      },
      "outputs": [],
      "source": [
        "vocab = list(vocab_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlvmXU1Kg43Z"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmhz_2WTm9km"
      },
      "outputs": [],
      "source": [
        "tok_questions = []\n",
        "\n",
        "for each in df['questions']:\n",
        "  sents = word_tokenize(each)\n",
        "  tok_questions.append(sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-cOSGkem9nE"
      },
      "outputs": [],
      "source": [
        "tok_answers = []\n",
        "\n",
        "for each in df['answers']:\n",
        "  sents = word_tokenize(each)\n",
        "  tok_answers.append(sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zganZ45-oxjR"
      },
      "outputs": [],
      "source": [
        "for each in tok_answers:\n",
        "  each.insert(0,\"<START>\")\n",
        "  each.insert(len(each),\"<END>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Vfu4lYm9pn",
        "outputId": "4242b589-d25a-4645-b338-6007b9083879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['well', 'i', 'thought', 'we', 'would', 'start', 'with', 'pronunciation', 'if', 'that', 'is', 'okay', 'with', 'you']\n",
            "\n",
            "['not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', 'please']\n",
            "\n",
            "['you', 'are', 'asking', 'me', 'out', 'that', 'is', 'so', 'cute', 'what', 'is', 'your', 'name', 'again']\n",
            "\n",
            "['no', 'no', 'it', 'is', 'my', 'fault', 'we', 'did', 'not', 'have', 'a', 'proper', 'introduction']\n",
            "\n",
            "['gosh', 'if', 'only', 'we', 'could', 'find', 'kat', 'a', 'boyfriend']\n",
            "\n",
            "['<START>', 'not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', 'please', '<END>']\n",
            "\n",
            "['<START>', 'okay', 'then', 'how', 'about', 'we', 'try', 'out', 'some', 'french', 'cuisine', 'saturday', 'night', '<END>']\n",
            "\n",
            "['<START>', 'forget', 'it', '<END>']\n",
            "\n",
            "['<START>', 'cameron', '<END>']\n",
            "\n",
            "['<START>', 'let', 'me', 'see', 'what', 'i', 'can', 'do', '<END>']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in tok_questions[:5]:\n",
        "  print(f'{i}',end='\\n\\n')\n",
        "for i in tok_answers[:5]:\n",
        "  print(f'{i}',end='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLn6-0IMjnJZ"
      },
      "outputs": [],
      "source": [
        "one_hot_questions = []\n",
        "\n",
        "for sentence in tok_questions:\n",
        "  temp = []\n",
        "  for each in sentence:\n",
        "    if each in vocab:\n",
        "      temp.append(vocab.index(each))\n",
        "    else:\n",
        "      temp.append(vocab.index('<OUT>'))\n",
        "  one_hot_questions.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs9gI-6qpR4B"
      },
      "outputs": [],
      "source": [
        "one_hot_answers = []\n",
        "\n",
        "for sentence in tok_answers:\n",
        "  temp = []\n",
        "  for each in sentence:\n",
        "    if each in vocab:\n",
        "      temp.append(vocab.index(each))\n",
        "    else:\n",
        "      temp.append(vocab.index('<OUT>'))\n",
        "  one_hot_answers.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfeP0bu7jnLn",
        "outputId": "caf5c08d-02f6-425f-aec2-886b123d34d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['well', 'i', 'thought', 'we', 'would', 'start', 'with', 'pronunciation', 'if', 'that', 'is', 'okay', 'with', 'you']\n",
            "['not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', 'please']\n",
            "['you', 'are', 'asking', 'me', 'out', 'that', 'is', 'so', 'cute', 'what', 'is', 'your', 'name', 'again']\n",
            "['no', 'no', 'it', 'is', 'my', 'fault', 'we', 'did', 'not', 'have', 'a', 'proper', 'introduction']\n",
            "['gosh', 'if', 'only', 'we', 'could', 'find', 'kat', 'a', 'boyfriend']\n",
            "\n",
            "[0, 1, 2, 3, 4, 5, 6, 13014, 7, 8, 9, 10, 6, 11]\n",
            "[12, 13, 14, 15, 16, 15, 17, 18, 19]\n",
            "[11, 20, 21, 22, 23, 8, 9, 24, 25, 26, 9, 27, 28, 29]\n",
            "[30, 30, 31, 9, 32, 33, 3, 34, 12, 35, 36, 37, 38]\n",
            "[39, 7, 40, 3, 41, 42, 43, 36, 44]\n"
          ]
        }
      ],
      "source": [
        "for i in tok_questions[:5]:\n",
        "  print(f'{i}',end='\\n')\n",
        "print()\n",
        "for i in one_hot_questions[:5]:\n",
        "  print(f'{i}',end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wnFt2IXqM1S",
        "outputId": "0c211dec-f743-4e7b-9f1a-937c941579e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<START>', 'not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', 'please', '<END>']\n",
            "['<START>', 'okay', 'then', 'how', 'about', 'we', 'try', 'out', 'some', 'french', 'cuisine', 'saturday', 'night', '<END>']\n",
            "['<START>', 'forget', 'it', '<END>']\n",
            "['<START>', 'cameron', '<END>']\n",
            "['<START>', 'let', 'me', 'see', 'what', 'i', 'can', 'do', '<END>']\n",
            "\n",
            "[255, 12, 13, 14, 15, 16, 15, 17, 18, 19, 256]\n",
            "[255, 10, 78, 52, 134, 3, 638, 23, 491, 245, 11649, 124, 147, 256]\n",
            "[255, 145, 31, 256]\n",
            "[255, 291, 256]\n",
            "[255, 179, 22, 217, 26, 1, 68, 83, 256]\n"
          ]
        }
      ],
      "source": [
        "for i in tok_answers[:5]:\n",
        "  print(f'{i}',end='\\n')\n",
        "print()\n",
        "for i in one_hot_answers[:5]:\n",
        "  print(f'{i}',end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK4BwGVqUjyh"
      },
      "outputs": [],
      "source": [
        "# # create one hot vector for each sentence. eg: [[32,34][12,54]]\n",
        "\n",
        "# tok = Tokenizer()\n",
        "# tok.fit_on_texts(sentences)\n",
        "# one_hot = tok.texts_to_sequences(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHplalzpf0LX",
        "outputId": "e4e1b2b3-9988-45f6-f857-071e6430e0d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "# find max length of sentences for padding\n",
        "\n",
        "maxi=0\n",
        "for i in one_hot_answers:\n",
        "    if len(i)>maxi:\n",
        "      maxi = len(i)\n",
        "print(maxi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sul2P6K8gd8H"
      },
      "outputs": [],
      "source": [
        "encoder_questions = pad_sequences(one_hot_questions, padding='post', maxlen=maxi)\n",
        "encoder_answers = pad_sequences(one_hot_answers, padding='post', maxlen=maxi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w5_kvNjwNEs"
      },
      "outputs": [],
      "source": [
        "decoder_answers = []\n",
        "\n",
        "for each in encoder_answers:\n",
        "  decoder_answers.append(each[1:])\n",
        "\n",
        "decoder_answers = pad_sequences(decoder_answers, padding='post', maxlen=maxi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNTRBY7lgkAi",
        "outputId": "bf171986-3c5a-46aa-ce53-27816b6b61a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[    0,     1,     2, ...,     0,     0,     0],\n",
              "       [   12,    13,    14, ...,     0,     0,     0],\n",
              "       [   11,    20,    21, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [ 1837, 13014,   353, ...,     0,     0,     0],\n",
              "       [   27,  2264,  1298, ...,     0,     0,     0],\n",
              "       [    1,    87,    81, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu8kyPSqrFLS",
        "outputId": "1d374840-e8dd-464b-f3a6-fb2b3f668878"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  255,    12,    13, ...,     0,     0,     0],\n",
              "       [  255,    10,    78, ...,     0,     0,     0],\n",
              "       [  255,   145,    31, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  255,    93,   493, ...,     0,     0,     0],\n",
              "       [  255,     1,    87, ...,     0,     0,     0],\n",
              "       [  255,  2623, 13014, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpYdhzmwxQsE",
        "outputId": "9fc426fe-291e-4920-d5d5-ea53db1cd2cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   12,    13,    14, ...,     0,     0,     0],\n",
              "       [   10,    78,    52, ...,     0,     0,     0],\n",
              "       [  145,    31,   256, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [   93,   493,   574, ...,     0,     0,     0],\n",
              "       [    1,    87,    81, ...,     0,     0,     0],\n",
              "       [ 2623, 13014,  1020, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WuCOgnb1v88",
        "outputId": "fa1adb44-825f-484d-b042-6ba0d66f8a4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(137344, 23)\n",
            "(137344, 23)\n",
            "(137344, 23)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(encoder_questions))\n",
        "print(np.shape(encoder_answers))\n",
        "print(np.shape(decoder_answers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBiFMpB9fjfF"
      },
      "outputs": [],
      "source": [
        "# create embedding matrix\n",
        "\n",
        "embed_dim = 300\n",
        "embed_matrix=np.zeros(shape=(vocab_size,embed_dim))\n",
        "for i,word in enumerate(vocab):\n",
        "  embed_vector=vocab_dict.get(word)\n",
        "  if embed_vector is not None:  # word is in the vocabulary learned by the w2v model\n",
        "    embed_matrix[i]=embed_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puyyxDJexu5Q"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFczWg_l24IC"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "    # Check accuracy\n",
        "    if(logs.get('acc') > 0.97):\n",
        "\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\nAccuracy is higher than 97% so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js4iZNW2xc-V"
      },
      "outputs": [],
      "source": [
        "# input of encoder and decoder\n",
        "enc_inp = Input(shape=(maxi,))\n",
        "dec_inp = Input(shape=(maxi,))\n",
        "\n",
        "# this layer embeds the english word in vector form\n",
        "embed = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=maxi, embeddings_initializer=Constant(embed_matrix))\n",
        "enc_embed = embed(enc_inp)\n",
        "\n",
        "# LSTM takes all the words at the same time but processes it one by one. The last _,_,_ is related to its previous state. So only final o/p is enough.\n",
        "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "enc_op, h, c = enc_lstm(enc_embed)\n",
        "enc_states = [h, c]\n",
        "\n",
        "# embedding is done in decoding and the LSTM return a series of sequence\n",
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "dense = Dense(vocab_size, activation='softmax')\n",
        "dense_op = dense(dec_op)\n",
        "\n",
        "model = Model([enc_inp, dec_inp], dense_op)\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['acc'],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R09ZOn9506Op",
        "outputId": "62a9f564-cc40-4f92-f02f-4e7528755ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "   5/4292 [..............................] - ETA: 3:05 - loss: 8.2477 - acc: 0.5663"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0141s vs `on_train_batch_end` time: 0.0217s). Check your callbacks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4292/4292 [==============================] - 124s 27ms/step - loss: 1.4556 - acc: 0.7608\n",
            "Epoch 2/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 1.3022 - acc: 0.7695\n",
            "Epoch 3/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 1.2320 - acc: 0.7732\n",
            "Epoch 4/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 1.1733 - acc: 0.7764\n",
            "Epoch 5/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 1.1189 - acc: 0.7800\n",
            "Epoch 6/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 1.0686 - acc: 0.7844\n",
            "Epoch 7/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 1.0228 - acc: 0.7895\n",
            "Epoch 8/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.9809 - acc: 0.7949\n",
            "Epoch 9/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.9420 - acc: 0.8003\n",
            "Epoch 10/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.9062 - acc: 0.8055\n",
            "Epoch 11/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.8730 - acc: 0.8106\n",
            "Epoch 12/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.8427 - acc: 0.8155\n",
            "Epoch 13/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.8144 - acc: 0.8203\n",
            "Epoch 14/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.7882 - acc: 0.8248\n",
            "Epoch 15/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.7642 - acc: 0.8290\n",
            "Epoch 16/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.7422 - acc: 0.8329\n",
            "Epoch 17/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.7219 - acc: 0.8367\n",
            "Epoch 18/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.7030 - acc: 0.8402\n",
            "Epoch 19/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.6862 - acc: 0.8432\n",
            "Epoch 20/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.6700 - acc: 0.8463\n",
            "Epoch 21/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.6557 - acc: 0.8489\n",
            "Epoch 22/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.6423 - acc: 0.8514\n",
            "Epoch 23/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.6294 - acc: 0.8540\n",
            "Epoch 24/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.6179 - acc: 0.8561\n",
            "Epoch 25/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.6074 - acc: 0.8581\n",
            "Epoch 26/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.5975 - acc: 0.8599\n",
            "Epoch 27/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.5884 - acc: 0.8619\n",
            "Epoch 28/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.5801 - acc: 0.8633\n",
            "Epoch 29/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.5721 - acc: 0.8649\n",
            "Epoch 30/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.5647 - acc: 0.8663\n",
            "Epoch 31/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.5578 - acc: 0.8676\n",
            "Epoch 32/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.5518 - acc: 0.8687\n",
            "Epoch 33/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.5456 - acc: 0.8697\n",
            "Epoch 34/35\n",
            "4292/4292 [==============================] - 120s 28ms/step - loss: 0.5401 - acc: 0.8709\n",
            "Epoch 35/35\n",
            "4292/4292 [==============================] - 119s 28ms/step - loss: 0.5345 - acc: 0.8719\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit([encoder_questions, encoder_answers],decoder_answers,epochs=35,batch_size=32,callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "M9vnwo3Q1WJy",
        "outputId": "f36f3af1-180e-4aa3-b8a7-bf930dc82f34"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "acc=hist.history['acc']\n",
        "loss=hist.history['loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, loss, 'b', \"Training Loss\")\n",
        "plt.title('Training accuracy & loss')\n",
        "plt.show()\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52dgrqPYWo2A"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CDBO8Hbdt5w"
      },
      "outputs": [],
      "source": [
        "enc_model = Model([enc_inp], enc_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(400,))\n",
        "decoder_state_input_c = Input(shape=(400,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = dec_lstm(dec_embed, initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "dec_model = Model([dec_inp]+ decoder_states_inputs, [decoder_outputs]+ decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hONWmjcwV2lA"
      },
      "outputs": [],
      "source": [
        "# [[32, 45, 65 ,77]] ---> [['hi', 'how', 'are', 'you']] ----> [['hi how are you']] ----> 'hi how are you'\n",
        "def predict(text):\n",
        "  text = clean_text(text)                                    # ---------> 'hi how are you'\n",
        "  text = text.split(' ')                                     # ---------> ['hi', 'how', 'are', 'you']\n",
        "  temp = []\n",
        "  for each in text:\n",
        "    if each in vocab:\n",
        "      temp.append(vocab.index(each))                         # ---------> vocab = list(vocab_dict.keys())\n",
        "    else:\n",
        "      temp.append(vocab.index('<OUT>'))\n",
        "  text = [temp]                                              # ---------> [[32, 45, 65 ,77]]\n",
        "  text = pad_sequences(text, padding='post', maxlen=maxi)    # ---------> [[32, 45, 65 ,77, 0, 0,0,.....,0]]\n",
        "  enc_model = Model([enc_inp], enc_states)\n",
        "  enc_pred = enc_model.predict(text)                         # ---------> return h,c after running LSTM. Shape: (400) each\n",
        "\n",
        "  empty_target_seq = np.zeros((1, 1))                        # ---------> [[0]] 2D list\n",
        "  empty_target_seq[0, 0] = vocab.index('<START>')            # ---------> index of 'start' so that model know it's time to predict \n",
        "  \n",
        "  stop = False\n",
        "  decoded_translation = ''\n",
        "\n",
        "  while not stop:\n",
        "    dec_outputs , h, c= dec_model.predict([empty_target_seq] + enc_pred )       # ---------> takes h,c with 'start' sequence as input\n",
        "    decoder_concat_input = dense(dec_outputs)                                   # ---------> shape is of vocab with softmax probab (1,1,13015)\n",
        "    sampled_word_index = np.argmax(decoder_concat_input[0, -1, :])              # ---------> reshapes into (13015,) and argmax\n",
        "\n",
        "    sampled_word = vocab[sampled_word_index] + ' '\n",
        "    if sampled_word != '<END> ':\n",
        "      decoded_translation += sampled_word\n",
        "    if sampled_word == '<END> ' or len(decoded_translation.split()) > maxi:\n",
        "      stop = True\n",
        "\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = sampled_word_index\n",
        "    enc_pred = [h,c]\n",
        "\n",
        "  return decoded_translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0DQuUuyozpA",
        "outputId": "305c8e67-2d78-470e-cfa4-dfda9bddc208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##########################################\n",
            "#          Welcome to Chatbot            #\n",
            "##########################################\n",
            "You : hi let's watch a movie\n",
            "Bot : no it is not like this \n",
            "==============================================\n",
            "You : don't you wanna watch a movie?\n",
            "Bot : i do not want to talk about it \n",
            "==============================================\n",
            "You : why not?\n",
            "Bot : i do not know \n",
            "==============================================\n",
            "You : you're rude\n",
            "Bot : i am afraid i do not know how to put it in your ear \n",
            "==============================================\n",
            "You : i hate you\n",
            "Bot : you do not know \n",
            "==============================================\n",
            "You : bye\n",
            "Bot : bye \n",
            "==============================================\n",
            "You : quit\n"
          ]
        }
      ],
      "source": [
        "print(\"##########################################\")\n",
        "print(\"#          Welcome to Chatbot            #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "while True:\n",
        "  text = input(\"You : \")\n",
        "  if text.lower() == 'quit':\n",
        "    break\n",
        "  answer = predict(text)\n",
        "  print(f'Bot : {answer}')\n",
        "  print(\"==============================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5jjMZkSuo1J"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD0FzwSLm1XJ"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1ktmyT2vTTd"
      },
      "outputs": [],
      "source": [
        "! mkdir 'Saved'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovj15VPhusKt"
      },
      "outputs": [],
      "source": [
        "with open('Saved/vocab_dict.pickle', 'wb') as handle:\n",
        "    pickle.dump(vocab_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIx-WE-_vY6E",
        "outputId": "592740f4-424c-4bb6-a392-75dbd79130be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  val = np.asanyarray(val)\n"
          ]
        }
      ],
      "source": [
        "# save the weights individually\n",
        "for layer in model.layers:\n",
        "    weights = layer.get_weights()\n",
        "    if weights != []:\n",
        "        np.savez(f'Saved/{layer.name}.npz', weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6oLqwglyW65"
      },
      "source": [
        "# Loading and predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx7XvzvpPR8W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense , Flatten , Embedding, Input, LSTM, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.initializers import Constant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkGEcsUijw4e",
        "outputId": "65273956-401f-4bb9-ecac-ecccef53f2cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.2\n",
            "1.21.6\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZduduQoxO6DP",
        "outputId": "f55ba090-97be-4d5d-86c6-ff30b9570675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Sxc6x7vPZCu"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Projects/Chatbot/Saved/vocab_dict.pickle', 'rb') as f:\n",
        "    vocab_dict = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HlpCl2nwLFC"
      },
      "outputs": [],
      "source": [
        "# load the weights\n",
        "w_embeddings = np.load('/content/drive/MyDrive/Projects/Chatbot/Saved/embedding.npz', allow_pickle=True)\n",
        "w_encoder_lstm = np.load('/content/drive/MyDrive/Projects/Chatbot/Saved/encoder_lstm.npz', allow_pickle=True)\n",
        "w_decoder_lstm = np.load('/content/drive/MyDrive/Projects/Chatbot/Saved/decoder_lstm.npz', allow_pickle=True)\n",
        "w_dense = np.load('/content/drive/MyDrive/Projects/Chatbot/Saved/dense.npz', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4rjFzoHQFcP"
      },
      "outputs": [],
      "source": [
        "### PREREQUISITES\n",
        "\n",
        "maxi = 23\n",
        "vocab = list(vocab_dict.keys())\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 300\n",
        "\n",
        "embed_matrix=np.zeros(shape=(vocab_size,embed_dim))\n",
        "for i,word in enumerate(vocab):\n",
        "  embed_vector=vocab_dict.get(word)\n",
        "  if embed_vector is not None:  # word is in the vocabulary learned by the w2v model\n",
        "    embed_matrix[i]=embed_vector\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"\\'m\", \" am\", text)\n",
        "  text = re.sub(r\"\\'s\", \" is\", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\n",
        "  text = re.sub(r\" 'bout\", \" about\", text)\n",
        "  text = re.sub(r\"gonna\", \"going to\", text)\n",
        "  text = re.sub(r\"gotta\", \"got to\", text)\n",
        "  text = re.sub(r\"won't\", \"will not\", text)\n",
        "  text = re.sub(r\"can't\", \"can not\", text)\n",
        "  text = re.sub(r\"n't\", \" not\", text)\n",
        "  text = re.sub(\"\\d+\",\"\",text) # remove numbers\n",
        "  text = re.sub(r\"[^\\w\\s]\", \"\", text) # remove punctuations\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLSM3eA4wwP_"
      },
      "outputs": [],
      "source": [
        "# input of encoder and decoder\n",
        "enc_inp = Input(shape=(maxi,))\n",
        "dec_inp = Input(shape=(maxi,))\n",
        "\n",
        "# this layer embeds the english word in vector form\n",
        "embed = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=maxi, embeddings_initializer=Constant(embed_matrix))\n",
        "enc_embed = embed(enc_inp)\n",
        "\n",
        "# LSTM takes all the words at the same time but processes it one by one. The last _,_,_ is related to its previous state. So only final o/p is enough.\n",
        "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "enc_op, h, c = enc_lstm(enc_embed)\n",
        "enc_states = [h, c]\n",
        "\n",
        "# embedding is done in decoding and the LSTM return a series of sequence\n",
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "dense = Dense(vocab_size, activation='softmax')\n",
        "dense_op = dense(dec_op)\n",
        "\n",
        "load_model = Model([enc_inp, dec_inp], dense_op)\n",
        "load_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['acc'],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoWmcAIAxCsu",
        "outputId": "d812d224-efb7-45ca-9815-7d85e6369ca8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f244514c8d0>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7f244514a990>,\n",
              " <keras.layers.embeddings.Embedding at 0x7f244514bd10>,\n",
              " <keras.layers.recurrent_v2.LSTM at 0x7f244514bc90>,\n",
              " <keras.layers.recurrent_v2.LSTM at 0x7f23d3578c50>,\n",
              " <keras.layers.core.dense.Dense at 0x7f23d2c47690>]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lZewknWxFKh"
      },
      "outputs": [],
      "source": [
        "# set the weights of the model\n",
        "\n",
        "load_model.layers[2].set_weights(w_embeddings['arr_0'])\n",
        "load_model.layers[3].set_weights(w_encoder_lstm['arr_0'])\n",
        "load_model.layers[4].set_weights(w_decoder_lstm['arr_0'])\n",
        "load_model.layers[5].set_weights(w_dense['arr_0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax858FVSxbnA"
      },
      "outputs": [],
      "source": [
        "enc_model = Model([enc_inp], enc_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(400,))\n",
        "decoder_state_input_c = Input(shape=(400,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = dec_lstm(dec_embed, initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "dec_model = Model([dec_inp]+ decoder_states_inputs, [decoder_outputs]+ decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqet4ORbx70Y"
      },
      "outputs": [],
      "source": [
        "# [[32, 45, 65 ,77]] ---> [['hi', 'how', 'are', 'you']] ----> [['hi how are you']] ----> 'hi how are you'\n",
        "def predict(text):\n",
        "  text = clean_text(text)                                    # ---------> 'hi how are you'\n",
        "  text = text.split(' ')                                     # ---------> ['hi', 'how', 'are', 'you']\n",
        "  temp = []\n",
        "  for each in text:\n",
        "    if each in vocab:\n",
        "      temp.append(vocab.index(each))                         # ---------> vocab = list(vocab_dict.keys())\n",
        "    else:\n",
        "      temp.append(vocab.index('<OUT>'))\n",
        "  text = [temp]                                              # ---------> [[32, 45, 65 ,77]]\n",
        "  text = pad_sequences(text, padding='post', maxlen=maxi)    # ---------> [[32, 45, 65 ,77, 0, 0,0,.....,0]]\n",
        "  enc_model = Model([enc_inp], enc_states)\n",
        "  enc_pred = enc_model.predict(text)                         # ---------> return h,c after running LSTM. Shape: (400) each\n",
        "\n",
        "  empty_target_seq = np.zeros((1, 1))                        # ---------> [[0]] 2D list\n",
        "  empty_target_seq[0, 0] = vocab.index('<START>')            # ---------> index of 'start' so that model know it's time to predict \n",
        "  \n",
        "  stop = False\n",
        "  decoded_translation = ''\n",
        "\n",
        "  while not stop:\n",
        "    dec_outputs , h, c= dec_model.predict([empty_target_seq] + enc_pred )       # ---------> takes h,c with 'start' sequence as input\n",
        "    decoder_concat_input = dense(dec_outputs)                                   # ---------> shape is of vocab with softmax probab (1,1,13015)\n",
        "    sampled_word_index = np.argmax(decoder_concat_input[0, -1, :])              # ---------> reshapes into (13015,) and argmax\n",
        "\n",
        "    sampled_word = vocab[sampled_word_index] + ' '\n",
        "    if sampled_word != '<END> ':\n",
        "      decoded_translation += sampled_word\n",
        "    if sampled_word == '<END> ' or len(decoded_translation.split()) > maxi:\n",
        "      stop = True\n",
        "\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = sampled_word_index\n",
        "    enc_pred = [h,c]\n",
        "\n",
        "  return decoded_translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-7TUg1F48V4",
        "outputId": "7315de3f-2d75-4568-9514-39658e31845d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##########################################\n",
            "#          Welcome to Chatbot            #\n",
            "##########################################\n",
            "You : hey how are you\n",
            "Bot : oh i am fine i am fine \n",
            "==============================================\n",
            "You : and what about mom?\n",
            "Bot : tell me where the hell do you go from \n",
            "==============================================\n",
            "You : how is mom?\n",
            "Bot : fine \n",
            "==============================================\n",
            "You : and dad?\n",
            "Bot : he is dead \n",
            "==============================================\n",
            "You : when?\n",
            "Bot : when i am free \n",
            "==============================================\n",
            "You : wanna fight?\n",
            "Bot : what is it \n",
            "==============================================\n",
            "You : fight with me\n",
            "Bot : where is it \n",
            "==============================================\n",
            "You : at my place\n",
            "Bot : that is fun \n",
            "==============================================\n",
            "You : you suck\n",
            "Bot : what \n",
            "==============================================\n",
            "You : quit\n"
          ]
        }
      ],
      "source": [
        "print(\"##########################################\")\n",
        "print(\"#          Welcome to Chatbot            #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "while True:\n",
        "  text = input(\"You : \")\n",
        "  if text.lower() == 'quit':\n",
        "    break\n",
        "  answer = predict(text)\n",
        "  print(f'Bot : {answer}')\n",
        "  print(\"==============================================\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "puyyxDJexu5Q",
        "52dgrqPYWo2A",
        "v5jjMZkSuo1J",
        "g6oLqwglyW65",
        "3A-oIeHHynW9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
